{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26a17f8f-6030-46a8-99a8-335b8bf9a696",
   "metadata": {},
   "source": [
    "# Install the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0f5aa50c-674e-4928-a831-1b1234f69207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./seleniumenv/lib/python3.10/site-packages (2.32.3)\n",
      "Requirement already satisfied: beautifulsoup4 in ./seleniumenv/lib/python3.10/site-packages (4.12.3)\n",
      "Requirement already satisfied: pandas in ./seleniumenv/lib/python3.10/site-packages (2.2.3)\n",
      "Requirement already satisfied: selenium in ./seleniumenv/lib/python3.10/site-packages (4.27.1)\n",
      "Requirement already satisfied: chromedriver_autoinstaller in ./seleniumenv/lib/python3.10/site-packages (0.6.4)\n",
      "Requirement already satisfied: torch in ./seleniumenv/lib/python3.10/site-packages (2.5.1)\n",
      "Requirement already satisfied: fake-useragent in ./seleniumenv/lib/python3.10/site-packages (2.0.2)\n",
      "Requirement already satisfied: python-dotenv in ./seleniumenv/lib/python3.10/site-packages (1.0.1)\n",
      "Requirement already satisfied: keybert in ./seleniumenv/lib/python3.10/site-packages (0.8.5)\n",
      "Requirement already satisfied: openpyxl in ./seleniumenv/lib/python3.10/site-packages (3.1.5)\n",
      "Collecting pymongo\n",
      "  Downloading pymongo-4.10.1-cp310-cp310-macosx_11_0_arm64.whl (835 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m835.7/835.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in ./seleniumenv/lib/python3.10/site-packages (from requests) (3.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./seleniumenv/lib/python3.10/site-packages (from requests) (2024.8.30)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./seleniumenv/lib/python3.10/site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./seleniumenv/lib/python3.10/site-packages (from requests) (2.2.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in ./seleniumenv/lib/python3.10/site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./seleniumenv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./seleniumenv/lib/python3.10/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: numpy>=1.22.4 in ./seleniumenv/lib/python3.10/site-packages (from pandas) (2.2.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./seleniumenv/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in ./seleniumenv/lib/python3.10/site-packages (from selenium) (0.11.1)\n",
      "Requirement already satisfied: websocket-client~=1.8 in ./seleniumenv/lib/python3.10/site-packages (from selenium) (1.8.0)\n",
      "Requirement already satisfied: typing_extensions~=4.9 in ./seleniumenv/lib/python3.10/site-packages (from selenium) (4.12.2)\n",
      "Requirement already satisfied: trio~=0.17 in ./seleniumenv/lib/python3.10/site-packages (from selenium) (0.27.0)\n",
      "Requirement already satisfied: packaging>=23.1 in ./seleniumenv/lib/python3.10/site-packages (from chromedriver_autoinstaller) (24.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in ./seleniumenv/lib/python3.10/site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: filelock in ./seleniumenv/lib/python3.10/site-packages (from torch) (3.16.1)\n",
      "Requirement already satisfied: jinja2 in ./seleniumenv/lib/python3.10/site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in ./seleniumenv/lib/python3.10/site-packages (from torch) (2024.10.0)\n",
      "Requirement already satisfied: networkx in ./seleniumenv/lib/python3.10/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in ./seleniumenv/lib/python3.10/site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: importlib-resources>=6.0 in ./seleniumenv/lib/python3.10/site-packages (from fake-useragent) (6.4.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.2 in ./seleniumenv/lib/python3.10/site-packages (from keybert) (1.6.0)\n",
      "Requirement already satisfied: sentence-transformers>=0.3.8 in ./seleniumenv/lib/python3.10/site-packages (from keybert) (3.3.1)\n",
      "Requirement already satisfied: rich>=10.4.0 in ./seleniumenv/lib/python3.10/site-packages (from keybert) (13.9.4)\n",
      "Requirement already satisfied: et-xmlfile in ./seleniumenv/lib/python3.10/site-packages (from openpyxl) (2.0.0)\n",
      "Collecting dnspython<3.0.0,>=1.16.0\n",
      "  Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "Requirement already satisfied: six>=1.5 in ./seleniumenv/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in ./seleniumenv/lib/python3.10/site-packages (from rich>=10.4.0->keybert) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in ./seleniumenv/lib/python3.10/site-packages (from rich>=10.4.0->keybert) (2.18.0)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./seleniumenv/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (3.5.0)\n",
      "Requirement already satisfied: scipy>=1.6.0 in ./seleniumenv/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (1.14.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./seleniumenv/lib/python3.10/site-packages (from scikit-learn>=0.22.2->keybert) (1.4.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in ./seleniumenv/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (4.47.0)\n",
      "Requirement already satisfied: tqdm in ./seleniumenv/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (4.67.1)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in ./seleniumenv/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (0.26.5)\n",
      "Requirement already satisfied: Pillow in ./seleniumenv/lib/python3.10/site-packages (from sentence-transformers>=0.3.8->keybert) (11.0.0)\n",
      "Requirement already satisfied: sniffio>=1.3.0 in ./seleniumenv/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup in ./seleniumenv/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.2.2)\n",
      "Requirement already satisfied: attrs>=23.2.0 in ./seleniumenv/lib/python3.10/site-packages (from trio~=0.17->selenium) (24.2.0)\n",
      "Requirement already satisfied: outcome in ./seleniumenv/lib/python3.10/site-packages (from trio~=0.17->selenium) (1.3.0.post0)\n",
      "Requirement already satisfied: sortedcontainers in ./seleniumenv/lib/python3.10/site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: wsproto>=0.14 in ./seleniumenv/lib/python3.10/site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: pysocks!=1.5.7,<2.0,>=1.5.6 in ./seleniumenv/lib/python3.10/site-packages (from urllib3<3,>=1.21.1->requests) (1.7.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in ./seleniumenv/lib/python3.10/site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./seleniumenv/lib/python3.10/site-packages (from huggingface-hub>=0.20.0->sentence-transformers>=0.3.8->keybert) (6.0.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in ./seleniumenv/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.4.0->keybert) (0.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./seleniumenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in ./seleniumenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.21.0)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in ./seleniumenv/lib/python3.10/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers>=0.3.8->keybert) (0.4.5)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in ./seleniumenv/lib/python3.10/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n",
      "Installing collected packages: dnspython, pymongo\n",
      "Successfully installed dnspython-2.7.0 pymongo-4.10.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/kuldeep/Documents/Projects/Jupyter Notebook/linkedinJobScrapper/seleniumenv/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests beautifulsoup4 pandas selenium chromedriver_autoinstaller torch fake-useragent python-dotenv keybert openpyxl pymongo openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca36063-74d8-47f1-9247-ccebe6436337",
   "metadata": {},
   "source": [
    "# Initialize the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f9e3b5-c7c0-4513-91e6-d82231cea9ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Driver initialized successfully\n"
     ]
    }
   ],
   "source": [
    "from selenium import webdriver\n",
    "import chromedriver_autoinstaller\n",
    "import sys\n",
    "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "# chrome_options.add_argument('--headless') # this is must\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "chromedriver_autoinstaller.install()\n",
    "\n",
    "driver = webdriver.Chrome(options=chrome_options)\n",
    "print(\"Driver initialized successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f123d30-bcb4-4845-80d0-9bedfb54bdaf",
   "metadata": {},
   "source": [
    "# Functions to login into the linkedin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d35234c-19ff-4d5c-8348-688ea7777929",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException;\n",
    "import logging\n",
    "def try_login(email, password):\n",
    "    # Step 1: Navigate to LinkedIn login page\n",
    "    driver.get(\"https://www.linkedin.com/login\")\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.ID, \"username\"))\n",
    "    )\n",
    "    # Step 2: Perform login\n",
    "    email_input = driver.find_element(By.ID, \"username\")\n",
    "    password_input = driver.find_element(By.ID, \"password\")\n",
    "    email_input.send_keys(email)\n",
    "    password_input.send_keys(password)\n",
    "    password_input.send_keys(Keys.RETURN)\n",
    "    sleep(3)\n",
    "    print(\"There might be a captcha.\")\n",
    "        \n",
    "    # options = Options()\n",
    "\n",
    "def enter_verification_code(verificationCode):\n",
    "    try:\n",
    "        verificationCodeInput = driver.find_element(By.ID, \"input__email_verification_pin\")\n",
    "        verificationCodeInput.send_keys(verificationCode)\n",
    "        print(\"Verification code box found\")\n",
    "        verificationCodeInput.send_keys(Keys.RETURN)\n",
    "    except NoSuchElementException:\n",
    "        print(\"No need to enter verification code\")\n",
    "    try:\n",
    "        WebDriverWait(driver, 10).until(\n",
    "            EC.presence_of_element_located((By.ID, \"global-nav-search\"))\n",
    "        )\n",
    "        logging.info(\"Login successful.\")\n",
    "    except TimeoutException:\n",
    "        logging.error(\"Login failed. Please check your credentials.\")\n",
    "        driver.quit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798a3201-55e9-4ccf-9f2c-5c1e1d9c6e47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "805c454b-6cb1-496e-9fd6-ad88d6f9dd58",
   "metadata": {},
   "source": [
    "### You may need to fill catpcha manually to login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a242f63-63d9-42af-9283-ffc73110dd13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There might be a captcha.\n"
     ]
    }
   ],
   "source": [
    "try_login(\"aakhyachaudhary2000@gmail.com\", \"Linked@1234\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b626df0-9767-4fb5-b274-2ee3cdc29a98",
   "metadata": {},
   "source": [
    "## Enter verification code(if recieved)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d97bdc2f-97a0-4a26-9a86-ee1746a10309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No need to enter verification code\n"
     ]
    }
   ],
   "source": [
    "#Pass verification code into the function \n",
    "enter_verification_code(\"Enter code here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ae8a4d-f1d7-4d48-b747-95d8b719cce0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "84a6b973-3898-43b0-bdf0-820053bc3c1f",
   "metadata": {},
   "source": [
    "# Utility function to scroll jobs to load them all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ec123194-7cc4-4474-85f4-a768cdbcb981",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_scrollable(element):\n",
    "    return driver.execute_script(\"return arguments[0].scrollHeight > arguments[0].clientHeight\", element)\n",
    "\n",
    "def scrollUntilAllJobsLoad(scrollableElm):\n",
    "    if is_scrollable(scrollableElm):\n",
    "        last_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollableElm)\n",
    "        while True:\n",
    "            # Scroll to the bottom of the child element\n",
    "            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight\", scrollableElm)\n",
    "            # Wait for new content to load\n",
    "            sleep(2)\n",
    "\n",
    "            # Check the new scroll height\n",
    "            new_height = driver.execute_script(\"return arguments[0].scrollHeight\", scrollableElm)\n",
    "            # Break if no new content is loaded\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "    \n",
    "        # print(\"\\tFinished scrolling the element.\")\n",
    "    else:\n",
    "        print(\"\\tPage is not scrollable.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dae4c46-07c7-416e-b48d-fa57bc2ab841",
   "metadata": {},
   "source": [
    "## Utility function to populate the dataframe with the jobs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dd6a7415-5719-45f1-8576-438ef1e73ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "            \n",
    "def populate_jobs_data(jobs, nbOfJobs):\n",
    "    job_data = {\n",
    "        \"Title\": [],\n",
    "        \"Company\": [],\n",
    "        \"Location\": [],\n",
    "        \"Link\": [],\n",
    "        \"Description\": [],\n",
    "    }\n",
    "    \n",
    "    totalJobs = len(jobs) if nbOfJobs > len(jobs) else nbOfJobs\n",
    "\n",
    "    for idx, job in enumerate(jobs[: totalJobs]):\n",
    "        try:\n",
    "            ActionChains(driver).move_to_element(job).perform()  \n",
    "            \n",
    "            job.click()\n",
    "            # visibility_of_element_located\n",
    "            titleElement = WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, \".job-view-layout h1\"))  # Title\n",
    "            )\n",
    "            title = titleElement.text\n",
    "            \n",
    "            companyElement = WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, \"[data-view-name='job-details-about-company-name-link']\"))  # Company\n",
    "            )\n",
    "            company = companyElement.text\n",
    "            \n",
    "            locationElement = WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, \".job-details-jobs-unified-top-card__primary-description-container span\"))  # Location\n",
    "            )\n",
    "            location = locationElement.text\n",
    "            \n",
    "            linkElement = WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.CSS_SELECTOR, \".job-view-layout h1 a\"))  # Link\n",
    "            )\n",
    "            link = linkElement.get_attribute(\"href\")\n",
    "            \n",
    "            descriptionElement = WebDriverWait(driver, 10).until(\n",
    "                EC.visibility_of_element_located((By.ID, \"job-details\"))  # Description\n",
    "            )\n",
    "            description = descriptionElement.text\n",
    "            \n",
    "            job_data[\"Company\"].append(company)\n",
    "            job_data[\"Title\"].append(title)\n",
    "            job_data[\"Location\"].append(location)\n",
    "            job_data[\"Link\"].append(link)\n",
    "            job_data[\"Description\"].append(description)\n",
    "            \n",
    "        except (ElementClickInterceptedException, TimeoutException, NoSuchElementException, StaleElementReferenceException) as e:\n",
    "            job_data[\"Company\"].append(\"\")\n",
    "            job_data[\"Title\"].append(\"\")\n",
    "            job_data[\"Location\"].append(\"\")\n",
    "            job_data[\"Link\"].append(\"\")\n",
    "            job_data[\"Description\"].append(\"\")\n",
    "            logging.warning(f\"Error extracting job {idx}: {e}\")\n",
    "            print(e)\n",
    "    \n",
    "    # print(\"\\tPopulating data completed.\")\n",
    "    return pd.DataFrame(job_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "45abba78-c700-4309-9e78-5cd886c830c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_jobs_from_page(nbOfJobsToScrapeFromPage):\n",
    "    jobsContainer = driver.find_element(By.CSS_SELECTOR, \".scaffold-layout__list > div\")\n",
    "    scrollUntilAllJobsLoad(jobsContainer)\n",
    "    jobs = driver.find_elements(By.CSS_SELECTOR, \".scaffold-layout__list > div > ul > li\")\n",
    "    return populate_jobs_data(jobs, nbOfJobsToScrapeFromPage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a2cfc907-8a15-4e35-ae4c-23c83d8a97d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOBS_PER_PAGE = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4637251-0394-4279-ac46-6a84039f0d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_to_next_page(page):\n",
    "    try:\n",
    "        print(f\"Waiting to navigate to page {page}\")\n",
    "        wait = WebDriverWait(driver, 10)\n",
    "        \n",
    "        pagination_button = wait.until(\n",
    "            EC.element_to_be_clickable((By.CSS_SELECTOR, f'button[aria-label=\"Page {page}\"]'))\n",
    "        )\n",
    "        pagination_button.click()\n",
    "        wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, \".job-view-layout h1\")))\n",
    "        print(f\"Navigated to {page} page\") \n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while navigating to page {page}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "af476c34-df15-466b-a0c4-f87df4660018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_linkedin_jobs(nbJobs, url = \"https://www.linkedin.com/jobs/search?keywords=Data+Center&location=United+States\"):\n",
    "    driver.get(url)\n",
    "    WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, \".scaffold-layout__list\"))\n",
    "    )\n",
    "    totalPagesToScrape = (nbJobs + JOBS_PER_PAGE - 1) // JOBS_PER_PAGE\n",
    "    currentPage = 1;\n",
    "    totalJobsDf = pd.DataFrame()\n",
    "    while True:\n",
    "        print(f\"Scraping from page: {currentPage}\")\n",
    "        nbOfJobsToScrapeFromPage = (nbJobs % JOBS_PER_PAGE) if totalPagesToScrape == currentPage else JOBS_PER_PAGE\n",
    "        currentPageJobs = pd.DataFrame()\n",
    "        # print(f\"\\tNumber of jobs that need to be fetch: {nbOfJobsToScrapeFromPage}\")\n",
    "        currentPageJobs = scrape_jobs_from_page(nbOfJobsToScrapeFromPage)\n",
    "        totalJobsDf = pd.concat([totalJobsDf, currentPageJobs], ignore_index=True)\n",
    "        if currentPage >= totalPagesToScrape or totalJobsDf.shape[0] >= nbJobs or totalJobsDf.shape[0] >= 1000:\n",
    "            break\n",
    "        move_to_next_page(currentPage + 1)\n",
    "        currentPage += 1\n",
    "    return totalJobsDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c90d488f-6b47-4cba-9190-e49ce48ca793",
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "\n",
    "class ExperienceFilter(Enum):\n",
    "    ALL = \"\"\n",
    "    INTERNSHIP = \"1\"\n",
    "    ENTRY_LEVEL = \"2\"\n",
    "    ASSOCIATE = \"3\"\n",
    "    MID_SENIOR_LEVEL = \"4\"\n",
    "    DIRECTOR = \"5\"\n",
    "    EXECUTIVE = \"6\"\n",
    "\n",
    "class JobPostTime(Enum):\n",
    "    ANY_TIME = \"\"\n",
    "    PAST_24_HOURS = \"2\"\n",
    "    PAST_WEEK = \"3\"\n",
    "    PAST_MONTH = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b1d80935-a20f-4a7d-82c5-40a4462836b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "JOB_EXCEL_FILE_INDEX = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9ff4663b-6d6c-4066-b437-d04cdb2de951",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_url_and_scrape_jobs(numberOfJobsToScrape, searchQuery = \"Data Center\", location = \"United States\"):\n",
    "    global JOB_EXCEL_FILE_INDEX\n",
    "    searchQuery = searchQuery.replace(\" \", \"%20\")\n",
    "    location = location.replace(\" \", \"%20\")\n",
    "    jobBaseUrl = f\"https://www.linkedin.com/jobs/search?keywords={searchQuery}&location={location}\"\n",
    "    jobsScraped = 0\n",
    "    doesFoundAllJobs = False\n",
    "    for experience in ExperienceFilter:\n",
    "        for postTime in JobPostTime:\n",
    "            url = jobBaseUrl + f\"&f_E={experience.value}&f_TPR={postTime.value}\"\n",
    "            print(f\"\\nScrapping from: {url}\")\n",
    "            jobsDF = scrape_linkedin_jobs(numberOfJobsToScrape, url)\n",
    "            jobsDF = jobsDF[~(jobsDF.eq('').all(axis=1))]\n",
    "            jobsDF.to_excel(f\"job_data_{JOB_EXCEL_FILE_INDEX}.xlsx\", index=False)\n",
    "            jobsScraped = jobsScraped + jobsDF.shape[0]\n",
    "            JOB_EXCEL_FILE_INDEX = JOB_EXCEL_FILE_INDEX + 1\n",
    "            if(jobsScraped >= numberOfJobsToScrape):\n",
    "                print(f\"Total jobs scraped: {jobsScraped}\")\n",
    "                return;\n",
    "    print(f\"You entered high number of jobs, we can scrape only {jobsScraped} number of jobs.\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639f51c4-40a4-480d-8d94-e45cf9e11b27",
   "metadata": {},
   "source": [
    "# Start scrapping the jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2781f5e9-05b8-4ca9-8c28-3a6044758956",
   "metadata": {},
   "outputs": [],
   "source": [
    "searchQuery = \"Data Center\"\n",
    "location = \"United States\"\n",
    "numberOfJobsToScrape = 25000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6b63dd5-c749-4191-8a6f-43229a599076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scrapping from: https://www.linkedin.com/jobs/search?keywords=Data%20Center&location=United%20States&f_E=&f_TPR=\n",
      "Scraping from page: 1\n",
      "Waiting to navigate to page 2\n",
      "Navigated to 2 page\n",
      "Scraping from page: 2\n",
      "Waiting to navigate to page 3\n",
      "Navigated to 3 page\n",
      "Scraping from page: 3\n",
      "Waiting to navigate to page 4\n",
      "Navigated to 4 page\n",
      "Scraping from page: 4\n",
      "Waiting to navigate to page 5\n",
      "Navigated to 5 page\n",
      "Scraping from page: 5\n",
      "Waiting to navigate to page 6\n",
      "Navigated to 6 page\n",
      "Scraping from page: 6\n",
      "Waiting to navigate to page 7\n",
      "Navigated to 7 page\n",
      "Scraping from page: 7\n",
      "Waiting to navigate to page 8\n",
      "Navigated to 8 page\n",
      "Scraping from page: 8\n",
      "Waiting to navigate to page 9\n",
      "Navigated to 9 page\n",
      "Scraping from page: 9\n",
      "Waiting to navigate to page 10\n",
      "Navigated to 10 page\n",
      "Scraping from page: 10\n",
      "Waiting to navigate to page 11\n",
      "Navigated to 11 page\n",
      "Scraping from page: 11\n",
      "Waiting to navigate to page 12\n",
      "Navigated to 12 page\n",
      "Scraping from page: 12\n",
      "Waiting to navigate to page 13\n",
      "Navigated to 13 page\n",
      "Scraping from page: 13\n",
      "Waiting to navigate to page 14\n",
      "Navigated to 14 page\n",
      "Scraping from page: 14\n",
      "Waiting to navigate to page 15\n",
      "Navigated to 15 page\n",
      "Scraping from page: 15\n",
      "Waiting to navigate to page 16\n",
      "Navigated to 16 page\n",
      "Scraping from page: 16\n",
      "Waiting to navigate to page 17\n",
      "Navigated to 17 page\n",
      "Scraping from page: 17\n",
      "Waiting to navigate to page 18\n",
      "Navigated to 18 page\n",
      "Scraping from page: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error extracting job 8: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102ba3184 cxxbridge1$str$ptr + 3626716\n",
      "1   chromedriver                        0x0000000102b9b9d4 cxxbridge1$str$ptr + 3596076\n",
      "2   chromedriver                        0x0000000102608968 cxxbridge1$string$len + 89228\n",
      "3   chromedriver                        0x000000010264cd50 cxxbridge1$string$len + 368756\n",
      "4   chromedriver                        0x00000001026865b4 cxxbridge1$string$len + 604376\n",
      "5   chromedriver                        0x0000000102641568 cxxbridge1$string$len + 321676\n",
      "6   chromedriver                        0x00000001026421b8 cxxbridge1$string$len + 324828\n",
      "7   chromedriver                        0x0000000102b6e9ac cxxbridge1$str$ptr + 3411716\n",
      "8   chromedriver                        0x0000000102b71ccc cxxbridge1$str$ptr + 3424804\n",
      "9   chromedriver                        0x0000000102b5586c cxxbridge1$str$ptr + 3308996\n",
      "10  chromedriver                        0x0000000102b7258c cxxbridge1$str$ptr + 3427044\n",
      "11  chromedriver                        0x0000000102b4709c cxxbridge1$str$ptr + 3249652\n",
      "12  chromedriver                        0x0000000102b8c4b8 cxxbridge1$str$ptr + 3533328\n",
      "13  chromedriver                        0x0000000102b8c634 cxxbridge1$str$ptr + 3533708\n",
      "14  chromedriver                        0x0000000102b9b648 cxxbridge1$str$ptr + 3595168\n",
      "15  libsystem_pthread.dylib             0x00000001840342e4 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x000000018402f0fc thread_start + 8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102ba3184 cxxbridge1$str$ptr + 3626716\n",
      "1   chromedriver                        0x0000000102b9b9d4 cxxbridge1$str$ptr + 3596076\n",
      "2   chromedriver                        0x0000000102608968 cxxbridge1$string$len + 89228\n",
      "3   chromedriver                        0x000000010264cd50 cxxbridge1$string$len + 368756\n",
      "4   chromedriver                        0x00000001026865b4 cxxbridge1$string$len + 604376\n",
      "5   chromedriver                        0x0000000102641568 cxxbridge1$string$len + 321676\n",
      "6   chromedriver                        0x00000001026421b8 cxxbridge1$string$len + 324828\n",
      "7   chromedriver                        0x0000000102b6e9ac cxxbridge1$str$ptr + 3411716\n",
      "8   chromedriver                        0x0000000102b71ccc cxxbridge1$str$ptr + 3424804\n",
      "9   chromedriver                        0x0000000102b5586c cxxbridge1$str$ptr + 3308996\n",
      "10  chromedriver                        0x0000000102b7258c cxxbridge1$str$ptr + 3427044\n",
      "11  chromedriver                        0x0000000102b4709c cxxbridge1$str$ptr + 3249652\n",
      "12  chromedriver                        0x0000000102b8c4b8 cxxbridge1$str$ptr + 3533328\n",
      "13  chromedriver                        0x0000000102b8c634 cxxbridge1$str$ptr + 3533708\n",
      "14  chromedriver                        0x0000000102b9b648 cxxbridge1$str$ptr + 3595168\n",
      "15  libsystem_pthread.dylib             0x00000001840342e4 _pthread_start + 136\n",
      "16  libsystem_pthread.dylib             0x000000018402f0fc thread_start + 8\n",
      "\n",
      "Waiting to navigate to page 19\n",
      "Navigated to 19 page\n",
      "Scraping from page: 19\n",
      "Waiting to navigate to page 20\n",
      "Navigated to 20 page\n",
      "Scraping from page: 20\n",
      "Waiting to navigate to page 21\n",
      "Navigated to 21 page\n",
      "Scraping from page: 21\n",
      "Waiting to navigate to page 22\n",
      "Navigated to 22 page\n",
      "Scraping from page: 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error extracting job 13: Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=131.0.6778.205); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102ba3184 cxxbridge1$str$ptr + 3626716\n",
      "1   chromedriver                        0x0000000102b9b9d4 cxxbridge1$str$ptr + 3596076\n",
      "2   chromedriver                        0x0000000102608968 cxxbridge1$string$len + 89228\n",
      "3   chromedriver                        0x000000010260d84c cxxbridge1$string$len + 109424\n",
      "4   chromedriver                        0x000000010260f89c cxxbridge1$string$len + 117696\n",
      "5   chromedriver                        0x000000010260f944 cxxbridge1$string$len + 117864\n",
      "6   chromedriver                        0x0000000102647f14 cxxbridge1$string$len + 348728\n",
      "7   chromedriver                        0x0000000102642ec8 cxxbridge1$string$len + 328172\n",
      "8   chromedriver                        0x00000001026865b4 cxxbridge1$string$len + 604376\n",
      "9   chromedriver                        0x0000000102641568 cxxbridge1$string$len + 321676\n",
      "10  chromedriver                        0x00000001026421b8 cxxbridge1$string$len + 324828\n",
      "11  chromedriver                        0x0000000102b6e9ac cxxbridge1$str$ptr + 3411716\n",
      "12  chromedriver                        0x0000000102b71ccc cxxbridge1$str$ptr + 3424804\n",
      "13  chromedriver                        0x0000000102b5586c cxxbridge1$str$ptr + 3308996\n",
      "14  chromedriver                        0x0000000102b7258c cxxbridge1$str$ptr + 3427044\n",
      "15  chromedriver                        0x0000000102b4709c cxxbridge1$str$ptr + 3249652\n",
      "16  chromedriver                        0x0000000102b8c4b8 cxxbridge1$str$ptr + 3533328\n",
      "17  chromedriver                        0x0000000102b8c634 cxxbridge1$str$ptr + 3533708\n",
      "18  chromedriver                        0x0000000102b9b648 cxxbridge1$str$ptr + 3595168\n",
      "19  libsystem_pthread.dylib             0x00000001840342e4 _pthread_start + 136\n",
      "20  libsystem_pthread.dylib             0x000000018402f0fc thread_start + 8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=131.0.6778.205); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102ba3184 cxxbridge1$str$ptr + 3626716\n",
      "1   chromedriver                        0x0000000102b9b9d4 cxxbridge1$str$ptr + 3596076\n",
      "2   chromedriver                        0x0000000102608968 cxxbridge1$string$len + 89228\n",
      "3   chromedriver                        0x000000010260d84c cxxbridge1$string$len + 109424\n",
      "4   chromedriver                        0x000000010260f89c cxxbridge1$string$len + 117696\n",
      "5   chromedriver                        0x000000010260f944 cxxbridge1$string$len + 117864\n",
      "6   chromedriver                        0x0000000102647f14 cxxbridge1$string$len + 348728\n",
      "7   chromedriver                        0x0000000102642ec8 cxxbridge1$string$len + 328172\n",
      "8   chromedriver                        0x00000001026865b4 cxxbridge1$string$len + 604376\n",
      "9   chromedriver                        0x0000000102641568 cxxbridge1$string$len + 321676\n",
      "10  chromedriver                        0x00000001026421b8 cxxbridge1$string$len + 324828\n",
      "11  chromedriver                        0x0000000102b6e9ac cxxbridge1$str$ptr + 3411716\n",
      "12  chromedriver                        0x0000000102b71ccc cxxbridge1$str$ptr + 3424804\n",
      "13  chromedriver                        0x0000000102b5586c cxxbridge1$str$ptr + 3308996\n",
      "14  chromedriver                        0x0000000102b7258c cxxbridge1$str$ptr + 3427044\n",
      "15  chromedriver                        0x0000000102b4709c cxxbridge1$str$ptr + 3249652\n",
      "16  chromedriver                        0x0000000102b8c4b8 cxxbridge1$str$ptr + 3533328\n",
      "17  chromedriver                        0x0000000102b8c634 cxxbridge1$str$ptr + 3533708\n",
      "18  chromedriver                        0x0000000102b9b648 cxxbridge1$str$ptr + 3595168\n",
      "19  libsystem_pthread.dylib             0x00000001840342e4 _pthread_start + 136\n",
      "20  libsystem_pthread.dylib             0x000000018402f0fc thread_start + 8\n",
      "\n",
      "Waiting to navigate to page 23\n",
      "Navigated to 23 page\n",
      "Scraping from page: 23\n",
      "Waiting to navigate to page 24\n",
      "Navigated to 24 page\n",
      "Scraping from page: 24\n",
      "Waiting to navigate to page 25\n",
      "Navigated to 25 page\n",
      "Scraping from page: 25\n",
      "Waiting to navigate to page 26\n",
      "Navigated to 26 page\n",
      "Scraping from page: 26\n",
      "Waiting to navigate to page 27\n",
      "Navigated to 27 page\n",
      "Scraping from page: 27\n",
      "Waiting to navigate to page 28\n",
      "Navigated to 28 page\n",
      "Scraping from page: 28\n",
      "Waiting to navigate to page 29\n",
      "Navigated to 29 page\n",
      "Scraping from page: 29\n",
      "Waiting to navigate to page 30\n",
      "Navigated to 30 page\n",
      "Scraping from page: 30\n",
      "Waiting to navigate to page 31\n",
      "Navigated to 31 page\n",
      "Scraping from page: 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error extracting job 1: Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=131.0.6778.205); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102ba3184 cxxbridge1$str$ptr + 3626716\n",
      "1   chromedriver                        0x0000000102b9b9d4 cxxbridge1$str$ptr + 3596076\n",
      "2   chromedriver                        0x0000000102608968 cxxbridge1$string$len + 89228\n",
      "3   chromedriver                        0x000000010260d84c cxxbridge1$string$len + 109424\n",
      "4   chromedriver                        0x000000010260f89c cxxbridge1$string$len + 117696\n",
      "5   chromedriver                        0x000000010260f944 cxxbridge1$string$len + 117864\n",
      "6   chromedriver                        0x0000000102647f14 cxxbridge1$string$len + 348728\n",
      "7   chromedriver                        0x0000000102642ec8 cxxbridge1$string$len + 328172\n",
      "8   chromedriver                        0x00000001026865b4 cxxbridge1$string$len + 604376\n",
      "9   chromedriver                        0x0000000102641568 cxxbridge1$string$len + 321676\n",
      "10  chromedriver                        0x00000001026421b8 cxxbridge1$string$len + 324828\n",
      "11  chromedriver                        0x0000000102b6e9ac cxxbridge1$str$ptr + 3411716\n",
      "12  chromedriver                        0x0000000102b71ccc cxxbridge1$str$ptr + 3424804\n",
      "13  chromedriver                        0x0000000102b5586c cxxbridge1$str$ptr + 3308996\n",
      "14  chromedriver                        0x0000000102b7258c cxxbridge1$str$ptr + 3427044\n",
      "15  chromedriver                        0x0000000102b4709c cxxbridge1$str$ptr + 3249652\n",
      "16  chromedriver                        0x0000000102b8c4b8 cxxbridge1$str$ptr + 3533328\n",
      "17  chromedriver                        0x0000000102b8c634 cxxbridge1$str$ptr + 3533708\n",
      "18  chromedriver                        0x0000000102b9b648 cxxbridge1$str$ptr + 3595168\n",
      "19  libsystem_pthread.dylib             0x00000001840342e4 _pthread_start + 136\n",
      "20  libsystem_pthread.dylib             0x000000018402f0fc thread_start + 8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=131.0.6778.205); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102ba3184 cxxbridge1$str$ptr + 3626716\n",
      "1   chromedriver                        0x0000000102b9b9d4 cxxbridge1$str$ptr + 3596076\n",
      "2   chromedriver                        0x0000000102608968 cxxbridge1$string$len + 89228\n",
      "3   chromedriver                        0x000000010260d84c cxxbridge1$string$len + 109424\n",
      "4   chromedriver                        0x000000010260f89c cxxbridge1$string$len + 117696\n",
      "5   chromedriver                        0x000000010260f944 cxxbridge1$string$len + 117864\n",
      "6   chromedriver                        0x0000000102647f14 cxxbridge1$string$len + 348728\n",
      "7   chromedriver                        0x0000000102642ec8 cxxbridge1$string$len + 328172\n",
      "8   chromedriver                        0x00000001026865b4 cxxbridge1$string$len + 604376\n",
      "9   chromedriver                        0x0000000102641568 cxxbridge1$string$len + 321676\n",
      "10  chromedriver                        0x00000001026421b8 cxxbridge1$string$len + 324828\n",
      "11  chromedriver                        0x0000000102b6e9ac cxxbridge1$str$ptr + 3411716\n",
      "12  chromedriver                        0x0000000102b71ccc cxxbridge1$str$ptr + 3424804\n",
      "13  chromedriver                        0x0000000102b5586c cxxbridge1$str$ptr + 3308996\n",
      "14  chromedriver                        0x0000000102b7258c cxxbridge1$str$ptr + 3427044\n",
      "15  chromedriver                        0x0000000102b4709c cxxbridge1$str$ptr + 3249652\n",
      "16  chromedriver                        0x0000000102b8c4b8 cxxbridge1$str$ptr + 3533328\n",
      "17  chromedriver                        0x0000000102b8c634 cxxbridge1$str$ptr + 3533708\n",
      "18  chromedriver                        0x0000000102b9b648 cxxbridge1$str$ptr + 3595168\n",
      "19  libsystem_pthread.dylib             0x00000001840342e4 _pthread_start + 136\n",
      "20  libsystem_pthread.dylib             0x000000018402f0fc thread_start + 8\n",
      "\n",
      "Waiting to navigate to page 32\n",
      "Navigated to 32 page\n",
      "Scraping from page: 32\n",
      "Waiting to navigate to page 33\n",
      "Navigated to 33 page\n",
      "Scraping from page: 33\n",
      "Waiting to navigate to page 34\n",
      "Navigated to 34 page\n",
      "Scraping from page: 34\n",
      "Waiting to navigate to page 35\n",
      "Navigated to 35 page\n",
      "Scraping from page: 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Error extracting job 9: Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=131.0.6778.205); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102ba3184 cxxbridge1$str$ptr + 3626716\n",
      "1   chromedriver                        0x0000000102b9b9d4 cxxbridge1$str$ptr + 3596076\n",
      "2   chromedriver                        0x0000000102608968 cxxbridge1$string$len + 89228\n",
      "3   chromedriver                        0x000000010260d84c cxxbridge1$string$len + 109424\n",
      "4   chromedriver                        0x000000010260f89c cxxbridge1$string$len + 117696\n",
      "5   chromedriver                        0x000000010260f944 cxxbridge1$string$len + 117864\n",
      "6   chromedriver                        0x0000000102647f14 cxxbridge1$string$len + 348728\n",
      "7   chromedriver                        0x0000000102642ec8 cxxbridge1$string$len + 328172\n",
      "8   chromedriver                        0x00000001026865b4 cxxbridge1$string$len + 604376\n",
      "9   chromedriver                        0x0000000102641568 cxxbridge1$string$len + 321676\n",
      "10  chromedriver                        0x00000001026421b8 cxxbridge1$string$len + 324828\n",
      "11  chromedriver                        0x0000000102b6e9ac cxxbridge1$str$ptr + 3411716\n",
      "12  chromedriver                        0x0000000102b71ccc cxxbridge1$str$ptr + 3424804\n",
      "13  chromedriver                        0x0000000102b5586c cxxbridge1$str$ptr + 3308996\n",
      "14  chromedriver                        0x0000000102b7258c cxxbridge1$str$ptr + 3427044\n",
      "15  chromedriver                        0x0000000102b4709c cxxbridge1$str$ptr + 3249652\n",
      "16  chromedriver                        0x0000000102b8c4b8 cxxbridge1$str$ptr + 3533328\n",
      "17  chromedriver                        0x0000000102b8c634 cxxbridge1$str$ptr + 3533708\n",
      "18  chromedriver                        0x0000000102b9b648 cxxbridge1$str$ptr + 3595168\n",
      "19  libsystem_pthread.dylib             0x00000001840342e4 _pthread_start + 136\n",
      "20  libsystem_pthread.dylib             0x000000018402f0fc thread_start + 8\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Message: stale element reference: stale element not found in the current frame\n",
      "  (Session info: chrome=131.0.6778.205); For documentation on this error, please visit: https://www.selenium.dev/documentation/webdriver/troubleshooting/errors#stale-element-reference-exception\n",
      "Stacktrace:\n",
      "0   chromedriver                        0x0000000102ba3184 cxxbridge1$str$ptr + 3626716\n",
      "1   chromedriver                        0x0000000102b9b9d4 cxxbridge1$str$ptr + 3596076\n",
      "2   chromedriver                        0x0000000102608968 cxxbridge1$string$len + 89228\n",
      "3   chromedriver                        0x000000010260d84c cxxbridge1$string$len + 109424\n",
      "4   chromedriver                        0x000000010260f89c cxxbridge1$string$len + 117696\n",
      "5   chromedriver                        0x000000010260f944 cxxbridge1$string$len + 117864\n",
      "6   chromedriver                        0x0000000102647f14 cxxbridge1$string$len + 348728\n",
      "7   chromedriver                        0x0000000102642ec8 cxxbridge1$string$len + 328172\n",
      "8   chromedriver                        0x00000001026865b4 cxxbridge1$string$len + 604376\n",
      "9   chromedriver                        0x0000000102641568 cxxbridge1$string$len + 321676\n",
      "10  chromedriver                        0x00000001026421b8 cxxbridge1$string$len + 324828\n",
      "11  chromedriver                        0x0000000102b6e9ac cxxbridge1$str$ptr + 3411716\n",
      "12  chromedriver                        0x0000000102b71ccc cxxbridge1$str$ptr + 3424804\n",
      "13  chromedriver                        0x0000000102b5586c cxxbridge1$str$ptr + 3308996\n",
      "14  chromedriver                        0x0000000102b7258c cxxbridge1$str$ptr + 3427044\n",
      "15  chromedriver                        0x0000000102b4709c cxxbridge1$str$ptr + 3249652\n",
      "16  chromedriver                        0x0000000102b8c4b8 cxxbridge1$str$ptr + 3533328\n",
      "17  chromedriver                        0x0000000102b8c634 cxxbridge1$str$ptr + 3533708\n",
      "18  chromedriver                        0x0000000102b9b648 cxxbridge1$str$ptr + 3595168\n",
      "19  libsystem_pthread.dylib             0x00000001840342e4 _pthread_start + 136\n",
      "20  libsystem_pthread.dylib             0x000000018402f0fc thread_start + 8\n",
      "\n",
      "Waiting to navigate to page 36\n",
      "Navigated to 36 page\n",
      "Scraping from page: 36\n",
      "Waiting to navigate to page 37\n",
      "Navigated to 37 page\n",
      "Scraping from page: 37\n",
      "Waiting to navigate to page 38\n",
      "Navigated to 38 page\n",
      "Scraping from page: 38\n",
      "Waiting to navigate to page 39\n",
      "Navigated to 39 page\n",
      "Scraping from page: 39\n",
      "Waiting to navigate to page 40\n",
      "Navigated to 40 page\n",
      "Scraping from page: 40\n",
      "\n",
      "Scrapping from: https://www.linkedin.com/jobs/search?keywords=Data%20Center&location=United%20States&f_E=&f_TPR=2\n",
      "Scraping from page: 1\n",
      "Waiting to navigate to page 2\n",
      "Navigated to 2 page\n",
      "Scraping from page: 2\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m jobsDF \u001b[38;5;241m=\u001b[39m \u001b[43mbuild_url_and_scrape_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumberOfJobsToScrape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msearchQuery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[27], line 12\u001b[0m, in \u001b[0;36mbuild_url_and_scrape_jobs\u001b[0;34m(numberOfJobsToScrape, searchQuery, location)\u001b[0m\n\u001b[1;32m     10\u001b[0m url \u001b[38;5;241m=\u001b[39m jobBaseUrl \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m&f_E=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperience\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m&f_TPR=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpostTime\u001b[38;5;241m.\u001b[39mvalue\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mScrapping from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 12\u001b[0m jobsDF \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_linkedin_jobs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumberOfJobsToScrape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m jobsDF\u001b[38;5;241m.\u001b[39mto_excel(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjob_data_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mJOB_EXCEL_FILE_INDEX\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     14\u001b[0m jobsScraped \u001b[38;5;241m=\u001b[39m jobsScraped \u001b[38;5;241m+\u001b[39m jobsDF\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n",
      "Cell \u001b[0;32mIn[24], line 14\u001b[0m, in \u001b[0;36mscrape_linkedin_jobs\u001b[0;34m(nbJobs, url)\u001b[0m\n\u001b[1;32m     12\u001b[0m currentPageJobs \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# print(f\"\\tNumber of jobs that need to be fetch: {nbOfJobsToScrapeFromPage}\")\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m currentPageJobs \u001b[38;5;241m=\u001b[39m \u001b[43mscrape_jobs_from_page\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbOfJobsToScrapeFromPage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m totalJobsDf \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([totalJobsDf, currentPageJobs], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m currentPage \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m totalPagesToScrape \u001b[38;5;129;01mor\u001b[39;00m totalJobsDf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m nbJobs \u001b[38;5;129;01mor\u001b[39;00m totalJobsDf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m:\n",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m, in \u001b[0;36mscrape_jobs_from_page\u001b[0;34m(nbOfJobsToScrapeFromPage)\u001b[0m\n\u001b[1;32m      3\u001b[0m scrollUntilAllJobsLoad(jobsContainer)\n\u001b[1;32m      4\u001b[0m jobs \u001b[38;5;241m=\u001b[39m driver\u001b[38;5;241m.\u001b[39mfind_elements(By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.scaffold-layout__list > div > ul > li\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpopulate_jobs_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbOfJobsToScrapeFromPage\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[20], line 28\u001b[0m, in \u001b[0;36mpopulate_jobs_data\u001b[0;34m(jobs, nbOfJobs)\u001b[0m\n\u001b[1;32m     23\u001b[0m titleElement \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[1;32m     24\u001b[0m     EC\u001b[38;5;241m.\u001b[39mvisibility_of_element_located((By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.job-view-layout h1\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Title\u001b[39;00m\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m title \u001b[38;5;241m=\u001b[39m titleElement\u001b[38;5;241m.\u001b[39mtext\n\u001b[0;32m---> 28\u001b[0m companyElement \u001b[38;5;241m=\u001b[39m \u001b[43mWebDriverWait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43muntil\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m    \u001b[49m\u001b[43mEC\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvisibility_of_element_located\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCSS_SELECTOR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m[data-view-name=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mjob-details-about-company-name-link\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m]\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Company\u001b[39;49;00m\n\u001b[1;32m     30\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m company \u001b[38;5;241m=\u001b[39m companyElement\u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m     33\u001b[0m locationElement \u001b[38;5;241m=\u001b[39m WebDriverWait(driver, \u001b[38;5;241m10\u001b[39m)\u001b[38;5;241m.\u001b[39muntil(\n\u001b[1;32m     34\u001b[0m     EC\u001b[38;5;241m.\u001b[39mvisibility_of_element_located((By\u001b[38;5;241m.\u001b[39mCSS_SELECTOR, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.job-details-jobs-unified-top-card__primary-description-container span\u001b[39m\u001b[38;5;124m\"\u001b[39m))  \u001b[38;5;66;03m# Location\u001b[39;00m\n\u001b[1;32m     35\u001b[0m )\n",
      "File \u001b[0;32m~/Documents/Projects/Jupyter Notebook/linkedinJobScrapper/seleniumenv/lib/python3.10/site-packages/selenium/webdriver/support/wait.py:104\u001b[0m, in \u001b[0;36mWebDriverWait.until\u001b[0;34m(self, method, message)\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time\u001b[38;5;241m.\u001b[39mmonotonic() \u001b[38;5;241m>\u001b[39m end_time:\n\u001b[1;32m    103\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m     \u001b[43mtime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_poll\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    105\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m TimeoutException(message, screen, stacktrace)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "build_url_and_scrape_jobs(numberOfJobsToScrape, searchQuery, location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b23cb5b7-431f-48c6-9170-71ee54256727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>Location</th>\n",
       "      <th>Link</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Plant Cyber Security Analyst</td>\n",
       "      <td>X-energy</td>\n",
       "      <td>Rockville, MD</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4099647478/...</td>\n",
       "      <td>About the job\\nX-energy LLC conducts a thoroug...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Physical Security Systems Technician - ...</td>\n",
       "      <td>VetJobs</td>\n",
       "      <td>San Jose, CA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4095124819/...</td>\n",
       "      <td>About the job\\nJob Description\\n\\nATTENTION MI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CAD Drafter</td>\n",
       "      <td>V2D Convergence</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4103451104/...</td>\n",
       "      <td>About the job\\nCompany Description\\n\\nMeade En...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Customer Service Analyst (Active SECRET Cleara...</td>\n",
       "      <td>Seneca Nation Group</td>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4083550577/...</td>\n",
       "      <td>About the job\\nGreat Hill Solutions is part of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Distributed Generation Demand Response Lead</td>\n",
       "      <td>Stream Data Centers</td>\n",
       "      <td>United States</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4075634185/...</td>\n",
       "      <td>About the job\\nFor 25 years, Stream Data Cente...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>Manager or Senior Manager, Managed Services</td>\n",
       "      <td>KPMG US</td>\n",
       "      <td>Portland, OR</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4104183428/...</td>\n",
       "      <td>About the job\\nAt KPMG, you can become an inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>Senior Network Security Engineer - MicroSegmen...</td>\n",
       "      <td>Mizuho</td>\n",
       "      <td>Iselin, NJ</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4080339704/...</td>\n",
       "      <td>About the job\\nJoin the Mizuho team as a Senio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>272</th>\n",
       "      <td>Manager or Senior Manager, Managed Services</td>\n",
       "      <td>KPMG US</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4110331870/...</td>\n",
       "      <td>About the job\\nAt KPMG, you can become an inte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>Fluid Systems Operations Engineer II</td>\n",
       "      <td>Blue Origin</td>\n",
       "      <td>Seattle, WA</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4090986740/...</td>\n",
       "      <td>About the job\\nAt Blue Origin, we envision mil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Manager or Senior Manager, Managed Services</td>\n",
       "      <td>KPMG US</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>https://www.linkedin.com/jobs/view/4110336317/...</td>\n",
       "      <td>About the job\\nAt KPMG, you can become an inte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>275 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Title              Company  \\\n",
       "0                         Plant Cyber Security Analyst             X-energy   \n",
       "1    Senior Physical Security Systems Technician - ...              VetJobs   \n",
       "2                                          CAD Drafter      V2D Convergence   \n",
       "3    Customer Service Analyst (Active SECRET Cleara...  Seneca Nation Group   \n",
       "4          Distributed Generation Demand Response Lead  Stream Data Centers   \n",
       "..                                                 ...                  ...   \n",
       "270        Manager or Senior Manager, Managed Services              KPMG US   \n",
       "271  Senior Network Security Engineer - MicroSegmen...               Mizuho   \n",
       "272        Manager or Senior Manager, Managed Services              KPMG US   \n",
       "273               Fluid Systems Operations Engineer II          Blue Origin   \n",
       "274        Manager or Senior Manager, Managed Services              KPMG US   \n",
       "\n",
       "          Location                                               Link  \\\n",
       "0    Rockville, MD  https://www.linkedin.com/jobs/view/4099647478/...   \n",
       "1     San Jose, CA  https://www.linkedin.com/jobs/view/4095124819/...   \n",
       "2       Austin, TX  https://www.linkedin.com/jobs/view/4103451104/...   \n",
       "3       Denver, CO  https://www.linkedin.com/jobs/view/4083550577/...   \n",
       "4    United States  https://www.linkedin.com/jobs/view/4075634185/...   \n",
       "..             ...                                                ...   \n",
       "270   Portland, OR  https://www.linkedin.com/jobs/view/4104183428/...   \n",
       "271     Iselin, NJ  https://www.linkedin.com/jobs/view/4080339704/...   \n",
       "272     Austin, TX  https://www.linkedin.com/jobs/view/4110331870/...   \n",
       "273    Seattle, WA  https://www.linkedin.com/jobs/view/4090986740/...   \n",
       "274    Chicago, IL  https://www.linkedin.com/jobs/view/4110336317/...   \n",
       "\n",
       "                                           Description  \n",
       "0    About the job\\nX-energy LLC conducts a thoroug...  \n",
       "1    About the job\\nJob Description\\n\\nATTENTION MI...  \n",
       "2    About the job\\nCompany Description\\n\\nMeade En...  \n",
       "3    About the job\\nGreat Hill Solutions is part of...  \n",
       "4    About the job\\nFor 25 years, Stream Data Cente...  \n",
       "..                                                 ...  \n",
       "270  About the job\\nAt KPMG, you can become an inte...  \n",
       "271  About the job\\nJoin the Mizuho team as a Senio...  \n",
       "272  About the job\\nAt KPMG, you can become an inte...  \n",
       "273  About the job\\nAt Blue Origin, we envision mil...  \n",
       "274  About the job\\nAt KPMG, you can become an inte...  \n",
       "\n",
       "[275 rows x 5 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3da5c9f7-5071-474b-ad4c-53067a84ea25",
   "metadata": {},
   "source": [
    "### Save the jobs in Mongo DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db39129e-16cb-4cba-8cfa-e2882b957470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "excel\n",
      "['./job_data_1.xlsx', './job_data_2.xlsx']\n",
      "processing ./job_data_1.xlsx file.\n",
      "dataframe = \n",
      "                                                 Title              Company  \\\n",
      "0                         Plant Cyber Security Analyst             X-energy   \n",
      "1    Senior Physical Security Systems Technician - ...              VetJobs   \n",
      "2                                          CAD Drafter      V2D Convergence   \n",
      "3    Customer Service Analyst (Active SECRET Cleara...  Seneca Nation Group   \n",
      "4          Distributed Generation Demand Response Lead  Stream Data Centers   \n",
      "..                                                 ...                  ...   \n",
      "995  Psychiatry Physician Job with OhioHealth in Ma...         PracticeLink   \n",
      "996              Director of Professional Services, RN  Concierge Home Care   \n",
      "997  Senior Manager of Infrastructure & Cloud Opera...    TransMedics, Inc.   \n",
      "998      Senior Manager, Network Capacity and Strategy  Madronich Dr Robert   \n",
      "999  Cardio-Thoracic Surgery Physician Job with Ohi...         PracticeLink   \n",
      "\n",
      "          Location                                               Link  \\\n",
      "0    Rockville, MD  https://www.linkedin.com/jobs/view/4099647478/...   \n",
      "1     San Jose, CA  https://www.linkedin.com/jobs/view/4095124819/...   \n",
      "2       Austin, TX  https://www.linkedin.com/jobs/view/4103451104/...   \n",
      "3       Denver, CO  https://www.linkedin.com/jobs/view/4083550577/...   \n",
      "4    United States  https://www.linkedin.com/jobs/view/4075634185/...   \n",
      "..             ...                                                ...   \n",
      "995  Mansfield, OH  https://www.linkedin.com/jobs/view/4099398994/...   \n",
      "996  Kissimmee, FL  https://www.linkedin.com/jobs/view/4105462709/...   \n",
      "997    Andover, MA  https://www.linkedin.com/jobs/view/4102587391/...   \n",
      "998   New York, NY  https://www.linkedin.com/jobs/view/4096751783/...   \n",
      "999  Mansfield, OH  https://www.linkedin.com/jobs/view/4099401300/...   \n",
      "\n",
      "                                           Description  \n",
      "0    About the job\\nX-energy LLC conducts a thoroug...  \n",
      "1    About the job\\nJob Description\\n\\nATTENTION MI...  \n",
      "2    About the job\\nCompany Description\\n\\nMeade En...  \n",
      "3    About the job\\nGreat Hill Solutions is part of...  \n",
      "4    About the job\\nFor 25 years, Stream Data Cente...  \n",
      "..                                                 ...  \n",
      "995  About the job\\nOhioHealth is adding a BE/ BC P...  \n",
      "996  About the job\\nConcierge Home Care is growing,...  \n",
      "997  About the job\\nJob Description\\n\\nSenior Manag...  \n",
      "998  About the job\\nOur mission at Talkspace is to ...  \n",
      "999  About the job\\nOhioHealth is adding a BE/BC Ca...  \n",
      "\n",
      "[1000 rows x 5 columns]\n",
      "Jobs from ././job_data_1.xlsx has been successfully inserted into MongoDB.\n",
      "processing ./job_data_2.xlsx file.\n",
      "dataframe = \n",
      "                                               Title           Company  \\\n",
      "0                             Summer 2025 Internship  174 Power Global   \n",
      "1  Project Manager/Business Analyst Intern- Summe...     Iron Mountain   \n",
      "\n",
      "                    Location  \\\n",
      "0  California, United States   \n",
      "1                Phoenix, AZ   \n",
      "\n",
      "                                                Link  \\\n",
      "0  https://www.linkedin.com/jobs/view/4108986000/...   \n",
      "1  https://www.linkedin.com/jobs/view/4075483331/...   \n",
      "\n",
      "                                         Description  \n",
      "0  About the job\\nCompany Overview\\n\\n174 Power G...  \n",
      "1  About the job\\nAt Iron Mountain we know that w...  \n",
      "Jobs from ././job_data_2.xlsx has been successfully inserted into MongoDB.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pymongo import MongoClient\n",
    "\n",
    "import glob\n",
    "import os\n",
    "\n",
    "folder_path = '.'\n",
    "excel_files = glob.glob(os.path.join(folder_path, '*.xlsx'))\n",
    "\n",
    "for file in excel_files:\n",
    "    print(f\"processing {file} file.\")\n",
    "    # Step 1: Read data from Excel\n",
    "    file_path = os.path.join(folder_path, file)  # Replace with your file path\n",
    "    df = pd.read_excel(file_path)\n",
    "    # Step 2: Connect to MongoDB\n",
    "    client = MongoClient('mongodb://localhost:27017/')  # Use your MongoDB connection string\n",
    "    db = client['local']  # Replace with your database name\n",
    "    collection = db['linked_jobs']  # Replace with your collection name\n",
    "    \n",
    "    # Step 3: Convert DataFrame to Dictionary\n",
    "    # Each row of the DataFrame will be converted into a dictionary\n",
    "    data_dict = df.to_dict(orient='records')\n",
    "    \n",
    "    # Step 4: Insert Data into MongoDB\n",
    "    collection.insert_many(data_dict)\n",
    "    \n",
    "    print(f\"Jobs from {file} has been successfully inserted into MongoDB.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3208e553-1b29-4295-b66e-8c0bc2381253",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "613357cc-71f6-4201-accb-c74f44e3a9c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec8491-3c28-435e-9d4f-e38048df8a18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c29f3e0-206e-4988-85d9-3db17ffd9b1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9d7ad092-019c-4248-a002-d711c81ba6fe",
   "metadata": {},
   "source": [
    "# Close the driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "5d776335-44ce-4cbc-85e7-b63a2ce4820d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d232a48b-1701-480a-b433-148748b43be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "div\n",
      "class: ['EqJniyihVFUsazZbXesrlrNpmyhxhQ']\n",
      "Found scrollable element. Scrolling...\n",
      "div\n",
      "class: ['EqJniyihVFUsazZbXesrlrNpmyhxhQ']\n",
      "Finished scrolling the element.\n",
      "Scrolling complete for all scrollable elements.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89a7f33-698d-4d67-b642-9b350cac0164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c02140-26f2-4ac1-b841-26d89d150ba0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "selKernel",
   "language": "python",
   "name": "selkernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
